{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pstringe/Bistromatic/blob/pstringe_master/lbcscraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8svqmVut3IdB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#1. Preliminary setup"
      ]
    },
    {
      "metadata": {
        "id": "CcdqjOH93Ufr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1023
        },
        "outputId": "2a5f32ad-8394-46b3-8b62-3065c2519b82"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install scrapy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scrapy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/12/a6197eaf97385e96fd8ec56627749a6229a9b3178ad73866a0b1fb377379/Scrapy-1.5.1-py2.py3-none-any.whl (249kB)\n",
            "\u001b[K    100% |████████████████████████████████| 256kB 7.7MB/s \n",
            "\u001b[?25hCollecting w3lib>=1.17.0 (from scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/37/94/40c93ad0cadac0f8cb729e1668823c71532fd4a7361b141aec535acb68e3/w3lib-1.19.0-py2.py3-none-any.whl\n",
            "Collecting Twisted>=13.1.0 (from scrapy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/0e/a72d85a55761c2c3ff1cb968143a2fd5f360220779ed90e0fadf4106d4f2/Twisted-18.9.0.tar.bz2 (3.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from scrapy) (4.2.5)\n",
            "Collecting queuelib (from scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/85/ae64e9145f39dd6d14f8af3fa809a270ef3729f3b90b3c0cf5aa242ab0d4/queuelib-1.5.0-py2.py3-none-any.whl\n",
            "Collecting cssselect>=0.9 (from scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
            "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/37/39aca520918ce1935bea9c356bcbb7ed7e52ad4e31bff9b943dfc8e7115b/PyDispatcher-2.0.5.tar.gz\n",
            "Collecting service-identity (from scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from scrapy) (1.11.0)\n",
            "Collecting pyOpenSSL (from scrapy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/af/9d29e6bd40823061aea2e0574ccb2fcf72bfd6130ce53d32773ec375458c/pyOpenSSL-18.0.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 25.2MB/s \n",
            "\u001b[?25hCollecting parsel>=1.1 (from scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/96/69/d1d5dba5e4fecd41ffd71345863ed36a45975812c06ba77798fc15db6a64/parsel-1.5.1-py2.py3-none-any.whl\n",
            "Collecting zope.interface>=4.4.2 (from Twisted>=13.1.0->scrapy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/17/1d198a6aaa9aa4590862fe3d3a2ed7dd808050cab4eebe8a2f2f813c1376/zope.interface-4.6.0-cp36-cp36m-manylinux1_x86_64.whl (167kB)\n",
            "\u001b[K    100% |████████████████████████████████| 174kB 31.3MB/s \n",
            "\u001b[?25hCollecting constantly>=15.1 (from Twisted>=13.1.0->scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
            "Collecting incremental>=16.10.1 (from Twisted>=13.1.0->scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n",
            "Collecting Automat>=0.3.0 (from Twisted>=13.1.0->scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/86/14c16bb98a5a3542ed8fed5d74fb064a902de3bdd98d6584b34553353c45/Automat-0.7.0-py2.py3-none-any.whl\n",
            "Collecting hyperlink>=17.1.1 (from Twisted>=13.1.0->scrapy)\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/b6/84d0c863ff81e8e7de87cff3bd8fd8f1054c227ce09af1b679a8b17a9274/hyperlink-18.0.0-py2.py3-none-any.whl\n",
            "Collecting PyHamcrest>=1.9.0 (from Twisted>=13.1.0->scrapy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d5/d37fd731b7d0e91afcc84577edeccf4638b4f9b82f5ffe2f8b62e2ddc609/PyHamcrest-1.9.0-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 25.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from Twisted>=13.1.0->scrapy) (18.2.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.6/dist-packages (from service-identity->scrapy) (0.4.4)\n",
            "Collecting cryptography (from service-identity->scrapy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/c7/99b33c53cf3f20a97a4c4bfd3ab66dcc93d99da0a97cc9597aa36ae6bb62/cryptography-2.4.2-cp34-abi3-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules in /usr/local/lib/python3.6/dist-packages (from service-identity->scrapy) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from zope.interface>=4.4.2->Twisted>=13.1.0->scrapy) (40.6.2)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.6/dist-packages (from hyperlink>=17.1.1->Twisted>=13.1.0->scrapy) (2.6)\n",
            "Collecting asn1crypto>=0.21.0 (from cryptography->service-identity->scrapy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 30.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.7 in /usr/local/lib/python3.6/dist-packages (from cryptography->service-identity->scrapy) (1.11.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.7->cryptography->service-identity->scrapy) (2.19)\n",
            "Building wheels for collected packages: Twisted, PyDispatcher\n",
            "  Running setup.py bdist_wheel for Twisted ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/57/2e/89/11ba83bc08ac30a5e3a6005f0310c78d231b96a270def88ca0\n",
            "  Running setup.py bdist_wheel for PyDispatcher ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/88/99/96/cfef6665f9cb1522ee6757ae5955feedf2fe25f1737f91fa7f\n",
            "Successfully built Twisted PyDispatcher\n",
            "Installing collected packages: w3lib, zope.interface, constantly, incremental, Automat, hyperlink, PyHamcrest, Twisted, queuelib, cssselect, PyDispatcher, asn1crypto, cryptography, service-identity, pyOpenSSL, parsel, scrapy\n",
            "Successfully installed Automat-0.7.0 PyDispatcher-2.0.5 PyHamcrest-1.9.0 Twisted-18.9.0 asn1crypto-0.24.0 constantly-15.1.0 cryptography-2.4.2 cssselect-1.0.3 hyperlink-18.0.0 incremental-17.5.0 parsel-1.5.1 pyOpenSSL-18.0.0 queuelib-1.5.0 scrapy-1.5.1 service-identity-18.1.0 w3lib-1.19.0 zope.interface-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2l40v34533Z2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#2. Import Modules"
      ]
    },
    {
      "metadata": {
        "id": "CT3Jm53U3_Rb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import scrapy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "59j0g_A94EN3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#3. Define Search Parameter Class"
      ]
    },
    {
      "metadata": {
        "id": "CJOdPn8K4RBL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#class for storing search parameters and generating request urls\n",
        "class Params():\n",
        "    def __init__(self):\n",
        "        self.category = None\n",
        "        self.text = None\n",
        "        self.region = None\n",
        "        self.location = None\n",
        "        self.price = []\n",
        "        self.setCategory()\n",
        "        self.setText()\n",
        "        self.setRegion()\n",
        "        self.setLocation()\n",
        "        #self.real_estate_type = setType()\n",
        "        self.setPrice()\n",
        "        #self.rooms = setRooms()\n",
        "        #self.search_in = setSearchIn()\n",
        "    \n",
        "    #consructs a url to initiate requests based on the search parameters\n",
        "    def getUrl(self):\n",
        "        url = \"https://www.leboncoin.fr/researche/?\"\n",
        "        if (self.category):\n",
        "            url += \"category={}&\".format(self.category)\n",
        "        if (self.text):\n",
        "            url += \"text={}&\".format(self.text)\n",
        "        if (self.region):\n",
        "            url += \"region={}&\".format(self.region)\n",
        "        if (self.location):\n",
        "            url += \"location={}&\".format(self.location)\n",
        "        if (self.price):\n",
        "            url += \"price={}&\".format(self.price)\n",
        "        return [url]\n",
        "    \n",
        "    #Here we set the region filter\n",
        "    def setRegion(self):\n",
        "        self.region = input(\"Enter {}, leave blank for nothing: \".format(\"the region\"))        \n",
        "    \n",
        "    #Here we set the location \n",
        "    def setLocation(self):\n",
        "        self.location = input(\"Enter {}, leave blank for nothing: \".format(\"a location\"))        \n",
        "   \n",
        "    #Here we set the \n",
        "    def setPrice(self):\n",
        "        self.price = {}\n",
        "        self.price[\"min\"] = input(\"Enter {}, leave blank for nothing (defaults to min): \".format(\"a minimum price\"))        \n",
        "        self.price[\"max\"] = input(\"Enter {}, leave blank for nothing (defaults to max): \".format(\"a maximum price\"))  \n",
        "        self.price[\"min\"] = self.price[\"min\"] if self.price[\"min\"] else None\n",
        "        self.price[\"max\"] = self.price[\"max\"] if self.price[\"max\"] else None\n",
        "    \n",
        "    #Categories are represented by numbers in the get request, eventually I'de like to allow both number and string input.\n",
        "    def setCategory(self):\n",
        "        self.category = input(\"Enter {}, leave blank for nothing: \".format(\"a category number\"))       \n",
        "    \n",
        "    #This sets the param that becomes the query a user would type in the search bar were they using the actual site.\n",
        "    def setText(self):\n",
        "        self.text = input(\"Enter {}, leave blank for nothing: \".format(\"the query text\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqovlM1p8nFk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#4. Define the Spider Class"
      ]
    },
    {
      "metadata": {
        "id": "siAxvxOO8wH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#the spider class\n",
        "class LBC(scrapy.Spider):\n",
        "    name = \"lbc\"\n",
        "    def start_requests(self):\n",
        "        params = Params()\n",
        "        urls = params.getUrl()\n",
        "        for url in urls:\n",
        "            yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "    #For now, I'll just request html, no parsing, I need to overcome the blocks first \n",
        "    def parse(self, response):\n",
        "        fileName = setFileName(response)\n",
        "        with open(filename, \"wb\") as f:\n",
        "        #I will have suceeded in this first task when I can write the html to files.\n",
        "            f.write(response.body)\n",
        "    \n",
        "    #Here we set the name we want the file to have that is being written to\n",
        "    def setFileName(response):\n",
        "        page = response.url.split('&')[-1]\n",
        "        if (page.split('=')):\n",
        "            page = page.split('=')[-1]\n",
        "        else:\n",
        "            page = 0\n",
        "        filename = \"page-{}\".format(page)\n",
        "        return filename"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}